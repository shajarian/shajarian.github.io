@article{demmese2024transfer,
  bibtex_show={true},
  title={Transfer learning with ResNet50 for malicious domains classification using image visualization},
  author={Demmese, Fikirte Ayalke and Shajarian, Shaghayegh and Khorsandroo, Sajad},
  abstract={The Internet has become a vital part of our daily lives, serving as a hub for global connectivity and a facilitator for seamless communication and information exchange. However, the rise of malicious domains presents a serious challenge, undermining the reliability of the Internet and posing risks to user safety. These malicious activities exploit the Domain Name System (DNS) to deceive users, leading to harmful activities such as spreading drive-by-download malware, operating botnets, creating phishing sites, and sending spam. In response to this growing threat, the application of Machine Learning (ML) techniques has proven to be highly effective. These methods excel in quickly and accurately detecting, classifying, and analyzing such threats. This paper explores the latest developments in using transfer learning for the classification of malicious domains, with a focus on image visualization as a key methodological approach. Our proposed solution has achieved a remarkable testing accuracy rate of 98.67%, demonstrating its effectiveness in detecting and classifying malicious domains.},
  journal={Discover Artificial Intelligence},
  volume={4},
  number={1},
  pages={1--14},
  year={2024},
  publisher={Springer},
  dimensions={true},
  selected={true},
  pdf={demmese2024transfer.pdf},
  html={https://link.springer.com/article/10.1007/s44163-024-00154-z},
  preview={1.png},
  }

  @misc{manthena2024explainablemalwareanalysisconcepts,
      title={Explainable Malware Analysis: Concepts, Approaches and Challenges}, 
      author={Harikha Manthena and Shaghayegh Shajarian and Jeffrey Kimmell and Mahmoud Abdelsalam and Sajad Khorsandroo and Maanak Gupta},
      abstract={Machine learning (ML) has seen exponential growth in recent years, finding applications in various domains such as finance, medicine, and cybersecurity. Malware remains a significant threat to modern computing, frequently used by attackers to compromise systems. While numerous machine learning-based approaches for malware detection achieve high performance, they often lack transparency and fail to explain their predictions. This is a critical drawback in malware analysis, where understanding the rationale behind detections is essential for security analysts to verify and disseminate information. Explainable AI (XAI) addresses this issue by maintaining high accuracy while producing models that provide clear, understandable explanations for their decisions. In this survey, we comprehensively review the current state-of-the-art ML-based malware detection techniques and popular XAI approaches. Additionally, we discuss research implementations and the challenges of explainable malware analysis. This theoretical survey serves as an entry point for researchers interested in XAI applications in malware detection. By analyzing recent advancements in explainable malware analysis, we offer a broad overview of the progress in this field, positioning our work as the first to extensively cover XAI methods for malware classification and detection.}
      year={2024},
      eprint={2409.13723},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      dimensions={true},
      selected={true},
      pdf={Explainable_Malware_Analysis.pdf},
      html={https://arxiv.org/abs/2409.13723}, 
      preview={1.jpg},
}


 #google_scholar_id={g1ckndEAAAAJ},